{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "478bbab9-7015-46eb-b94c-321884e710b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import Node2Vec\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.utils import degree, to_networkx\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b058cc6b-84e7-43c7-bbf8-30f93c55a593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\436348439.py:1: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  embeddings_1 = pd.read_json('embeddings_with_cluster1.json',lines=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\436348439.py:1: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  embeddings_1 = pd.read_json('embeddings_with_cluster1.json',lines=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\436348439.py:1: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  embeddings_1 = pd.read_json('embeddings_with_cluster1.json',lines=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\436348439.py:3: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  embeddings_2 = pd.read_json('embeddings_with_cluster2.json',lines=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\436348439.py:3: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  embeddings_2 = pd.read_json('embeddings_with_cluster2.json',lines=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\436348439.py:3: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  embeddings_2 = pd.read_json('embeddings_with_cluster2.json',lines=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\436348439.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  embeddings_3 = pd.read_json('embeddings_with_cluster3.json',lines=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\436348439.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  embeddings_3 = pd.read_json('embeddings_with_cluster3.json',lines=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\436348439.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  embeddings_3 = pd.read_json('embeddings_with_cluster3.json',lines=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.049728</td>\n",
       "      <td>0.220807</td>\n",
       "      <td>-0.009551</td>\n",
       "      <td>-0.260663</td>\n",
       "      <td>0.061310</td>\n",
       "      <td>0.031595</td>\n",
       "      <td>-0.149981</td>\n",
       "      <td>0.082681</td>\n",
       "      <td>-0.009008</td>\n",
       "      <td>0.039538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077505</td>\n",
       "      <td>0.160976</td>\n",
       "      <td>-0.041870</td>\n",
       "      <td>0.289285</td>\n",
       "      <td>-0.138164</td>\n",
       "      <td>-0.098474</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.104904</td>\n",
       "      <td>0.175890</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.151118</td>\n",
       "      <td>0.167657</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>-0.098236</td>\n",
       "      <td>0.169692</td>\n",
       "      <td>0.039468</td>\n",
       "      <td>-0.045907</td>\n",
       "      <td>0.097608</td>\n",
       "      <td>0.106262</td>\n",
       "      <td>0.014770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095225</td>\n",
       "      <td>-0.127120</td>\n",
       "      <td>0.037120</td>\n",
       "      <td>0.039927</td>\n",
       "      <td>-0.015724</td>\n",
       "      <td>0.232021</td>\n",
       "      <td>-0.162908</td>\n",
       "      <td>0.086416</td>\n",
       "      <td>0.187216</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.404190</td>\n",
       "      <td>-0.269846</td>\n",
       "      <td>0.082369</td>\n",
       "      <td>0.156145</td>\n",
       "      <td>-0.057768</td>\n",
       "      <td>0.189231</td>\n",
       "      <td>-0.005160</td>\n",
       "      <td>0.101423</td>\n",
       "      <td>-0.240075</td>\n",
       "      <td>0.043559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139599</td>\n",
       "      <td>-0.355075</td>\n",
       "      <td>0.384469</td>\n",
       "      <td>0.124133</td>\n",
       "      <td>0.036653</td>\n",
       "      <td>-0.125443</td>\n",
       "      <td>0.153743</td>\n",
       "      <td>0.325689</td>\n",
       "      <td>-0.356468</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017481</td>\n",
       "      <td>0.048374</td>\n",
       "      <td>-0.077696</td>\n",
       "      <td>-0.417364</td>\n",
       "      <td>0.004395</td>\n",
       "      <td>-0.183351</td>\n",
       "      <td>0.104363</td>\n",
       "      <td>0.192619</td>\n",
       "      <td>0.220743</td>\n",
       "      <td>0.220823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132920</td>\n",
       "      <td>-0.194306</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>-0.052717</td>\n",
       "      <td>-0.032724</td>\n",
       "      <td>-0.241660</td>\n",
       "      <td>0.055065</td>\n",
       "      <td>0.093820</td>\n",
       "      <td>0.044434</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.069057</td>\n",
       "      <td>-0.209454</td>\n",
       "      <td>-0.048993</td>\n",
       "      <td>0.038812</td>\n",
       "      <td>-0.070603</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.179880</td>\n",
       "      <td>-0.093794</td>\n",
       "      <td>0.033769</td>\n",
       "      <td>-0.056118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.163917</td>\n",
       "      <td>-0.072509</td>\n",
       "      <td>0.098020</td>\n",
       "      <td>-0.157713</td>\n",
       "      <td>0.008254</td>\n",
       "      <td>-0.054138</td>\n",
       "      <td>0.184190</td>\n",
       "      <td>0.102305</td>\n",
       "      <td>-0.113230</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.049728  0.220807 -0.009551 -0.260663  0.061310  0.031595 -0.149981   \n",
       "1  0.151118  0.167657  0.081400 -0.098236  0.169692  0.039468 -0.045907   \n",
       "2  0.404190 -0.269846  0.082369  0.156145 -0.057768  0.189231 -0.005160   \n",
       "3  0.017481  0.048374 -0.077696 -0.417364  0.004395 -0.183351  0.104363   \n",
       "4  0.069057 -0.209454 -0.048993  0.038812 -0.070603  0.002607  0.179880   \n",
       "\n",
       "          7         8         9  ...       119       120       121       122  \\\n",
       "0  0.082681 -0.009008  0.039538  ...  0.077505  0.160976 -0.041870  0.289285   \n",
       "1  0.097608  0.106262  0.014770  ... -0.095225 -0.127120  0.037120  0.039927   \n",
       "2  0.101423 -0.240075  0.043559  ... -0.139599 -0.355075  0.384469  0.124133   \n",
       "3  0.192619  0.220743  0.220823  ... -0.132920 -0.194306  0.093333 -0.052717   \n",
       "4 -0.093794  0.033769 -0.056118  ... -0.163917 -0.072509  0.098020 -0.157713   \n",
       "\n",
       "        123       124       125       126       127  cluster_label  \n",
       "0 -0.138164 -0.098474  0.041500  0.104904  0.175890              2  \n",
       "1 -0.015724  0.232021 -0.162908  0.086416  0.187216              2  \n",
       "2  0.036653 -0.125443  0.153743  0.325689 -0.356468              2  \n",
       "3 -0.032724 -0.241660  0.055065  0.093820  0.044434             -1  \n",
       "4  0.008254 -0.054138  0.184190  0.102305 -0.113230              2  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_1 = pd.read_json('embeddings_with_cluster1.json',lines=True)\n",
    "embeddings_1.head()\n",
    "embeddings_2 = pd.read_json('embeddings_with_cluster2.json',lines=True)\n",
    "embeddings_2.head()\n",
    "embeddings_3 = pd.read_json('embeddings_with_cluster3.json',lines=True)\n",
    "embeddings_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "991816c1-60a8-4081-b0de-5a5d825bc6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\2560387486.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[f'{column}_rank'] = df_test[column].rank(method='average',ascending = False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\2560387486.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[f'{column}_rank'] = df_test[column].rank(method='average',ascending = False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\2560387486.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[f'{column}_rank'] = df_test[column].rank(method='average',ascending = False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\2560387486.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[f'{column}_rank'] = df_test[column].rank(method='average',ascending = False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\2560387486.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[f'{col}_norm'] = (df_test[col] - df_test[col].min()) / (df_test[col].max() - df_test[col].min())\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\2560387486.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[f'{col}_norm'] = (df_test[col] - df_test[col].min()) / (df_test[col].max() - df_test[col].min())\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\2560387486.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[f'{col}_norm'] = (df_test[col] - df_test[col].min()) / (df_test[col].max() - df_test[col].min())\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\2560387486.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[f'{col}_norm'] = (df_test[col] - df_test[col].min()) / (df_test[col].max() - df_test[col].min())\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19972\\2560387486.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['composite_brokerage_score'] = df_test[['betweenness_centrality_norm', 'degree_norm', 'eigenvector_centrality_norm', 'pagerank_norm']].mean(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>betweenness_centrality</th>\n",
       "      <th>degree</th>\n",
       "      <th>eigenvector_centrality</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>betweenness_centrality_rank</th>\n",
       "      <th>degree_rank</th>\n",
       "      <th>eigenvector_centrality_rank</th>\n",
       "      <th>pagerank_rank</th>\n",
       "      <th>betweenness_centrality_norm</th>\n",
       "      <th>degree_norm</th>\n",
       "      <th>eigenvector_centrality_norm</th>\n",
       "      <th>pagerank_norm</th>\n",
       "      <th>composite_brokerage_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188082</th>\n",
       "      <td>CUST36405209</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.510221</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>8455.0</td>\n",
       "      <td>4778.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.178731</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.672888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cust_id  betweenness_centrality  degree  eigenvector_centrality  \\\n",
       "188082  CUST36405209                0.000167    20.0                0.510221   \n",
       "\n",
       "        pagerank  betweenness_centrality_rank  degree_rank  \\\n",
       "188082  0.000142                       8455.0       4778.5   \n",
       "\n",
       "        eigenvector_centrality_rank  pagerank_rank  \\\n",
       "188082                          1.0            1.0   \n",
       "\n",
       "        betweenness_centrality_norm  degree_norm  eigenvector_centrality_norm  \\\n",
       "188082                     0.178731     0.512821                          1.0   \n",
       "\n",
       "        pagerank_norm  composite_brokerage_score  \n",
       "188082            1.0                   0.672888  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies_full_df_1 = pd.read_csv('final_upd_3.csv')\n",
    "anomalies_full_df_1.drop('Unnamed: 0', axis =1, inplace = True)\n",
    "anomalies_full_df = pd.read_csv('final_upd_2.csv')\n",
    "anomalies_full_df.drop('Unnamed: 0', axis =1, inplace = True)\n",
    "df_test = anomalies_full_df[['cust_id','betweenness_centrality','degree','eigenvector_centrality','pagerank']]\n",
    "for column in ['betweenness_centrality', 'degree', 'eigenvector_centrality', 'pagerank']:\n",
    "    df_test[f'{column}_rank'] = df_test[column].rank(method='average',ascending = False)\n",
    "df_test.head(1)\n",
    "df_test_sorted = df_test.sort_values(by=['degree_rank', 'betweenness_centrality_rank', 'eigenvector_centrality_rank', 'pagerank_rank'], ascending=True)\n",
    "# High betweenness centrality nodes\n",
    "high_betweenness_nodes = df_test[df_test['betweenness_centrality'] > df_test['betweenness_centrality'].quantile(0.9)]\n",
    "# Normalizing centrality measures\n",
    "for col in ['betweenness_centrality', 'degree', 'eigenvector_centrality', 'pagerank']:\n",
    "    df_test[f'{col}_norm'] = (df_test[col] - df_test[col].min()) / (df_test[col].max() - df_test[col].min())\n",
    "\n",
    "# Creating a composite score\n",
    "df_test['composite_brokerage_score'] = df_test[['betweenness_centrality_norm', 'degree_norm', 'eigenvector_centrality_norm', 'pagerank_norm']].mean(axis=1)\n",
    "\n",
    "# Identifying top brokerage nodes based on the composite score\n",
    "top_brokerage_nodes = df_test.sort_values(by='composite_brokerage_score', ascending=False)\n",
    "top_brokerage_nodes.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4afccaf1-db18-453a-ad88-b72ab2e0f6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1_percent_cutoff = top_brokerage_nodes['composite_brokerage_score'].quantile(0.999)  # Adjust quantile for different cutoffs\n",
    "highly_influential_nodes = top_brokerage_nodes[top_brokerage_nodes['composite_brokerage_score'] >= top_1_percent_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a601948-fbd8-4944-bed5-a096782775be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cust_id_to_index.pkl', 'rb') as f:\n",
    "    cust_id_to_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a54dbd2a-60e4-4bd5-8faa-cf3de3bb55ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_combined = pd.read_csv('transactions_combined_up.csv').drop('Unnamed: 0',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "530fcd31-b897-407e-9f7e-939e81d30288",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_combined['sender_idx'] = transactions_combined['cust_id_sender'].map(cust_id_to_index)\n",
    "transactions_combined['receiver_idx'] = transactions_combined['cust_id_receiver'].map(cust_id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f345e9cb-5bb3-465c-ad98-1471baf11c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id_sender</th>\n",
       "      <th>cust_id_receiver</th>\n",
       "      <th>amount</th>\n",
       "      <th>count</th>\n",
       "      <th>sender_idx</th>\n",
       "      <th>receiver_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUST10000513</td>\n",
       "      <td>CUST13934055</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>118080</td>\n",
       "      <td>76636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cust_id_sender cust_id_receiver  amount  count  sender_idx  receiver_idx\n",
       "0   CUST10000513     CUST13934055   360.0      1      118080         76636"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_combined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c2c63e36-1f9a-4dad-8f8e-884f33345022",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_df = anomalies_full_df_1[anomalies_full_df_1.anomaly == -1]\n",
    "df_merged = anomalies_df.merge(highly_influential_nodes[['cust_id','composite_brokerage_score']], how = 'inner', on = 'cust_id')\n",
    "influential_customers = df_merged.cust_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dbbfb49f-e359-4da1-be71-acd761cbd21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUST34310812</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUST29461884</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUST53667999</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUST52962125</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUST97925988</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>CUST99278393</td>\n",
       "      <td>133196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>CUST98291483</td>\n",
       "      <td>138265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>CUST99675035</td>\n",
       "      <td>138458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>CUST34886918</td>\n",
       "      <td>150698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>CUST94371161</td>\n",
       "      <td>173535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cust_id   index\n",
       "0    CUST34310812     224\n",
       "1    CUST29461884     257\n",
       "2    CUST53667999     341\n",
       "3    CUST52962125     404\n",
       "4    CUST97925988    1102\n",
       "..            ...     ...\n",
       "188  CUST99278393  133196\n",
       "189  CUST98291483  138265\n",
       "190  CUST99675035  138458\n",
       "191  CUST34886918  150698\n",
       "192  CUST94371161  173535\n",
       "\n",
       "[193 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influential_mappings = {cust_id: index for cust_id, index in cust_id_to_index.items() if cust_id in influential_customers}\n",
    "influential_df = pd.DataFrame(list(influential_mappings.items()), columns=['cust_id', 'index'])\n",
    "influential_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cddcc000-b8dc-448e-befc-e63aeb44b40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    influential_cust_id                  similar_cust_ids\n",
      "0          CUST98901965      [CUST35476414, CUST17046649]\n",
      "1          CUST71268159      [CUST41167081, CUST85018083]\n",
      "2          CUST94760680  [EXTERNAL861334, EXTERNAL884936]\n",
      "3          CUST26911489  [EXTERNAL431313, EXTERNAL730236]\n",
      "4          CUST48605422      [CUST37416122, CUST57301076]\n",
      "..                  ...                               ...\n",
      "188        CUST73212501    [EXTERNAL165458, CUST63538915]\n",
      "189        CUST36405209  [EXTERNAL934888, EXTERNAL304920]\n",
      "190        CUST17148894      [CUST12980531, CUST20671743]\n",
      "191        CUST41581393    [CUST42393992, EXTERNAL540048]\n",
      "192        CUST28168926      [CUST97630737, CUST34893846]\n",
      "\n",
      "[193 rows x 2 columns]\n",
      "    influential_cust_id similar_cust_ids\n",
      "0          CUST98901965     CUST35476414\n",
      "1          CUST98901965     CUST17046649\n",
      "2          CUST71268159     CUST41167081\n",
      "3          CUST71268159     CUST85018083\n",
      "4          CUST94760680   EXTERNAL861334\n",
      "..                  ...              ...\n",
      "381        CUST17148894     CUST20671743\n",
      "382        CUST41581393     CUST42393992\n",
      "383        CUST41581393   EXTERNAL540048\n",
      "384        CUST28168926     CUST97630737\n",
      "385        CUST28168926     CUST34893846\n",
      "\n",
      "[386 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Convert embeddings DataFrame to a PyTorch tensor for efficient computation\n",
    "embeddings_tensor = torch.tensor(embeddings_1.values).float()\n",
    "\n",
    "# Initialize a list to store data about influential customers and their top similar nodes\n",
    "data = {'influential_cust_id': [], 'similar_cust_ids': []}\n",
    "\n",
    "# Iterate over influential customers\n",
    "for cust_id in influential_customers:\n",
    "    # Get the index of the current influential customer from the cust_id_to_index mapping\n",
    "    index = cust_id_to_index[cust_id]\n",
    "    \n",
    "    # Extract the embedding for the current influential customer\n",
    "    influential_embedding = embeddings_tensor[index].unsqueeze(0)  # Add batch dimension for cosine similarity calculation\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    normalized_embeddings = torch.nn.functional.normalize(embeddings_tensor, p=2, dim=1)\n",
    "    normalized_influential_embedding = torch.nn.functional.normalize(influential_embedding, p=2, dim=1)\n",
    "    similarity_scores = torch.mm(normalized_influential_embedding, normalized_embeddings.transpose(0, 1))\n",
    "    \n",
    "    # Set the self-similarity to a low value to exclude it from top results\n",
    "    similarity_scores[0, index] = -1\n",
    "    # Find indices of the top 5 similar nodes, excluding the highest one as it's the node itself\n",
    "    top_similar_indices = torch.topk(similarity_scores, k=3, largest=True).indices[0][1:]\n",
    "\n",
    "    # Convert indices back to customer IDs using a list comprehension and the cust_id_to_index mapping\n",
    "    top_similar_cust_ids = [cust_id for cust_id, idx in cust_id_to_index.items() if idx in top_similar_indices.tolist()]\n",
    "    \n",
    "    # Append the results to our data structure\n",
    "    data['influential_cust_id'].append(cust_id)\n",
    "    data['similar_cust_ids'].append(top_similar_cust_ids)\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "relationships_df = pd.DataFrame(data)\n",
    "\n",
    "# If you prefer each similar customer ID to be in separate rows:\n",
    "relationships_df_exploded = relationships_df.explode('similar_cust_ids').reset_index(drop=True)\n",
    "\n",
    "print(relationships_df)\n",
    "print(relationships_df_exploded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3f033dc4-6964-4684-9674-3965825595b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = pd.unique(relationships_df_exploded[['influential_cust_id', 'similar_cust_ids']].values.ravel('K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c0a1d84b-55e0-4894-807e-f4dd224bfaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Convert embeddings DataFrame to a PyTorch tensor for efficient computation\n",
    "embeddings_tensor = torch.tensor(embeddings_2.values).float()\n",
    "\n",
    "# Initialize a list to store data about influential customers and their top similar nodes\n",
    "data = {'influential_cust_id': [], 'similar_cust_ids': []}\n",
    "\n",
    "# Iterate over influential customers\n",
    "for cust_id in influential_customers:\n",
    "    # Get the index of the current influential customer from the cust_id_to_index mapping\n",
    "    index = cust_id_to_index[cust_id]\n",
    "    \n",
    "    # Extract the embedding for the current influential customer\n",
    "    influential_embedding = embeddings_tensor[index].unsqueeze(0)  # Add batch dimension for cosine similarity calculation\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    normalized_embeddings = torch.nn.functional.normalize(embeddings_tensor, p=2, dim=1)\n",
    "    normalized_influential_embedding = torch.nn.functional.normalize(influential_embedding, p=2, dim=1)\n",
    "    similarity_scores = torch.mm(normalized_influential_embedding, normalized_embeddings.transpose(0, 1))\n",
    "    \n",
    "    # Set the self-similarity to a low value to exclude it from top results\n",
    "    similarity_scores[0, index] = -1\n",
    "    # Find indices of the top 5 similar nodes, excluding the highest one as it's the node itself\n",
    "    top_similar_indices = torch.topk(similarity_scores, k=3, largest=True).indices[0][1:]\n",
    "\n",
    "    # Convert indices back to customer IDs using a list comprehension and the cust_id_to_index mapping\n",
    "    top_similar_cust_ids = [cust_id for cust_id, idx in cust_id_to_index.items() if idx in top_similar_indices.tolist()]\n",
    "    \n",
    "    # Append the results to our data structure\n",
    "    data['influential_cust_id'].append(cust_id)\n",
    "    data['similar_cust_ids'].append(top_similar_cust_ids)\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "relationships_df_2 = pd.DataFrame(data)\n",
    "\n",
    "relationships_df_exploded_2 = relationships_df.explode('similar_cust_ids').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "eb08915f-ad3b-43ea-a07f-1e3a189e3546",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_2 = pd.unique(relationships_df_exploded_2[['influential_cust_id', 'similar_cust_ids']].values.ravel('K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "aa974e8f-c058-4610-8d99-a80de617d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Convert embeddings DataFrame to a PyTorch tensor for efficient computation\n",
    "embeddings_tensor = torch.tensor(embeddings_3.values).float()\n",
    "\n",
    "# Initialize a list to store data about influential customers and their top similar nodes\n",
    "data = {'influential_cust_id': [], 'similar_cust_ids': []}\n",
    "\n",
    "# Iterate over influential customers\n",
    "for cust_id in influential_customers:\n",
    "    # Get the index of the current influential customer from the cust_id_to_index mapping\n",
    "    index = cust_id_to_index[cust_id]\n",
    "    \n",
    "    # Extract the embedding for the current influential customer\n",
    "    influential_embedding = embeddings_tensor[index].unsqueeze(0)  # Add batch dimension for cosine similarity calculation\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    normalized_embeddings = torch.nn.functional.normalize(embeddings_tensor, p=2, dim=1)\n",
    "    normalized_influential_embedding = torch.nn.functional.normalize(influential_embedding, p=2, dim=1)\n",
    "    similarity_scores = torch.mm(normalized_influential_embedding, normalized_embeddings.transpose(0, 1))\n",
    "    \n",
    "    # Set the self-similarity to a low value to exclude it from top results\n",
    "    similarity_scores[0, index] = -1\n",
    "    # Find indices of the top 5 similar nodes, excluding the highest one as it's the node itself\n",
    "    top_similar_indices = torch.topk(similarity_scores, k=3, largest=True).indices[0][1:]\n",
    "\n",
    "    # Convert indices back to customer IDs using a list comprehension and the cust_id_to_index mapping\n",
    "    top_similar_cust_ids = [cust_id for cust_id, idx in cust_id_to_index.items() if idx in top_similar_indices.tolist()]\n",
    "    \n",
    "    # Append the results to our data structure\n",
    "    data['influential_cust_id'].append(cust_id)\n",
    "    data['similar_cust_ids'].append(top_similar_cust_ids)\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "relationships_df_3 = pd.DataFrame(data)\n",
    "\n",
    "# If you prefer each similar customer ID to be in separate rows:\n",
    "relationships_df_exploded_3 = relationships_df.explode('similar_cust_ids').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bc72e394-9104-40a7-a58b-c6552275eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_3 = pd.unique(relationships_df_exploded_3[['influential_cust_id', 'similar_cust_ids']].values.ravel('K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e0a4ec2e-be3e-44f0-b395-7bd35be69157",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_influential = list(set(unique_values) & set(unique_values_2) & set(unique_values_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1e803389-39ca-4c98-9c81-7df80c5c3521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "# Create an empty graph. Use nx.DiGraph() for a directed graph if that's more appropriate for your data.\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add edges to the graph from the transactions DataFrame\n",
    "for _, transaction in transactions_combined.iterrows():\n",
    "    sender_id = transaction['cust_id_sender']\n",
    "    receiver_id = transaction['cust_id_receiver']\n",
    "    amount = transaction['amount']  # Assuming this is how you wish to use the transaction amount, e.g., as edge weight\n",
    "    \n",
    "    # Add edge with the amount as edge attribute (weight)\n",
    "    G.add_edge(sender_id, receiver_id, weight=amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1fc451cd-d8d7-49c1-89f5-cc782db86b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Direct Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1ccfa-1943-483c-9451-ef9d77778144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Assuming 'G' is your graph and 'influential_customers' is a list of customer IDs\n",
    "nodes_to_include = set(common_influential)\n",
    "\n",
    "for customer in unique_values:\n",
    "    # Get direct neighbors of 'customer'\n",
    "    neighbors = set(G.neighbors(customer))\n",
    "    \n",
    "    # Add these neighbors to our set\n",
    "    nodes_to_include.update(neighbors)\n",
    "\n",
    "# Create the subgraph including all nodes identified (influential customers and their direct neighbors)\n",
    "subG_direct = G.subgraph(nodes_to_include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eea9b9-e052-4bf9-ad19-638471017c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subG_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "da80c1b0-b837-4aac-b7b0-a2e0a3c5f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_data = pd.DataFrame(subG_direct.edges(data=True), columns=['cust_id_sender', 'cust_id_receiver', 'amount'])\n",
    "edges_data.to_csv(\"subG_direct_edges.csv\", index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb2417be-fd66-4c89-a1bd-c928b36ddd64",
   "metadata": {},
   "source": [
    "##Indirect Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "af27162f-d07c-4e2f-9763-fb8f7230d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_to_include_ind = set(common_influential)\n",
    "distance = 2 # Adjust based on how \"far\" you want to go in terms of indirect connections\n",
    "\n",
    "for customer in influential_customers:\n",
    "    # BFS to get all nodes within 'distance' steps from 'customer'\n",
    "    bfs_nodes = nx.single_source_shortest_path_length(G, customer,distance)\n",
    "    \n",
    "    # Add these nodes to our set\n",
    "    nodes_to_include_ind.update(bfs_nodes.keys())\n",
    "\n",
    "# Create the subgraph including all nodes identified\n",
    "subG_indirect = G.subgraph(nodes_to_include_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cb0acbb2-a62b-4160-b520-57c8a8184e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39813"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subG_indirect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4e1f8abf-1dff-4c48-9cf9-2170fade1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_data = pd.DataFrame(subG_indirect.edges(data=True), columns=['cust_id_sender', 'cust_id_receiver', 'amount'])\n",
    "edges_data.to_csv(\"subG_indirect_edges.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "713b110d-636c-4645-90a5-4ca1af412cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id_sender</th>\n",
       "      <th>targecust_id_receivert</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUST54801958</td>\n",
       "      <td>CUST43814376</td>\n",
       "      <td>{'weight': 502.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXTERNAL261114</td>\n",
       "      <td>CUST67282733</td>\n",
       "      <td>{'weight': 293.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXTERNAL118720</td>\n",
       "      <td>CUST83708217</td>\n",
       "      <td>{'weight': 1132.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXTERNAL118720</td>\n",
       "      <td>CUST95405296</td>\n",
       "      <td>{'weight': 1134.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUST92080684</td>\n",
       "      <td>CUST75674030</td>\n",
       "      <td>{'weight': 12.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75146</th>\n",
       "      <td>CUST90034020</td>\n",
       "      <td>CUST73418006</td>\n",
       "      <td>{'weight': 959.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75147</th>\n",
       "      <td>CUST62924281</td>\n",
       "      <td>CUST54381300</td>\n",
       "      <td>{'weight': 2690.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75148</th>\n",
       "      <td>EXTERNAL881945</td>\n",
       "      <td>CUST39444554</td>\n",
       "      <td>{'weight': 290.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75149</th>\n",
       "      <td>CUST30991673</td>\n",
       "      <td>EXTERNAL165302</td>\n",
       "      <td>{'weight': 939.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75150</th>\n",
       "      <td>EXTERNAL697717</td>\n",
       "      <td>CUST51031361</td>\n",
       "      <td>{'weight': 706.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75151 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cust_id_sender targecust_id_receivert              amount\n",
       "0        CUST54801958           CUST43814376   {'weight': 502.0}\n",
       "1      EXTERNAL261114           CUST67282733   {'weight': 293.5}\n",
       "2      EXTERNAL118720           CUST83708217  {'weight': 1132.0}\n",
       "3      EXTERNAL118720           CUST95405296  {'weight': 1134.0}\n",
       "4        CUST92080684           CUST75674030    {'weight': 12.0}\n",
       "...               ...                    ...                 ...\n",
       "75146    CUST90034020           CUST73418006   {'weight': 959.0}\n",
       "75147    CUST62924281           CUST54381300  {'weight': 2690.0}\n",
       "75148  EXTERNAL881945           CUST39444554   {'weight': 290.0}\n",
       "75149    CUST30991673         EXTERNAL165302   {'weight': 939.0}\n",
       "75150  EXTERNAL697717           CUST51031361   {'weight': 706.0}\n",
       "\n",
       "[75151 rows x 3 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e7a2f8-1d0f-4ad2-ac2a-8e46ef7a7bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
